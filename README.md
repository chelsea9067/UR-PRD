# UnmannedRetail-PickReturn-Dataset
Our dataset comprises 2,103 labeled action instances spanning three categories: Item Pickup, Item Return, and Other Action. These instances were extracted from recorded videos, with each instance having a duration ranging from 1 to 10 sec-onds. In total, UR-PRD contains 101,830 annotated frames.
	UR-PRD captures real-world challenges in unmanned retail through five sce-narios: Normal (all actions, minimal occlusion, varying lighting/viewpoints), Occlusion (hand/item partly blocked), Small Items (smaller, hard-to-detect items), Err-Pickup (pickup without holding items), and Err-Return (return while still holding items). We split Normal, Occlusion, and Small Items into 80% training and 20% testing, while Err-Pickup and Err-Return are allocated exclu-sively to the test set to rigorously assess generalization.
